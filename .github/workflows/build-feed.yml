name: Build weekly Sri Lanka news feeds

on:
  schedule:
    - cron: "10 1 * * 5"  # 01:10 UTC every Friday (after Nuwan's build)
  workflow_dispatch:

permissions:
  contents: write

jobs:
  build:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout this repo
        uses: actions/checkout@v4

      - name: Install Python deps
        run: |
          python -m pip install --upgrade pip
          pip install requests markdown tzdata

      - name: Generate RSS/JSON feeds (clean, spaced, pretty)
        env:
          SRC_RAW: https://raw.githubusercontent.com/nuuuwan/lk_news_digest/main/README.md
          SRC_README: https://github.com/nuuuwan/lk_news_digest/blob/main/README.md
          SRC_REPO: https://github.com/nuuuwan/lk_news_digest
          TZ_NAME: Asia/Colombo
        run: |
          python - << 'PY'
          import os
          import re
          import json
          import email.utils
          from datetime import datetime, timezone
          from zoneinfo import ZoneInfo

          import requests
          from markdown import markdown
          from xml.dom.minidom import Document

          SRC_RAW = os.environ["SRC_RAW"]
          SRC_README = os.environ["SRC_README"]
          SRC_REPO = os.environ["SRC_REPO"]
          TZ_NAME = os.environ.get("TZ_NAME", "Asia/Colombo")

          owner, repo = os.environ.get("GITHUB_REPOSITORY", "owner/repo").split("/", 1)
          pages_base = f"https://{owner}.github.io/{repo}"

          # --- Fetch upstream README ---
          resp = requests.get(SRC_RAW, timeout=60)
          resp.raise_for_status()
          md = resp.text

          # --- Extract metadata ---

          # last_updated-YYYY--MM--DD_HH:MM:SS
          last_updated = None
          m = re.search(
              r"last_updated-([0-9]{4}--[0-9]{2}--[0-9]{2}_[0-9]{2}:[0-9]{2}:[0-9]{2})",
              md,
          )
          if m:
            raw = m.group(1).replace("--", "-")
            try:
              last_updated = datetime.strptime(raw, "%Y-%m-%d_%H:%M:%S").replace(
                  tzinfo=ZoneInfo(TZ_NAME)
              )
            except Exception:
              last_updated = None

          # from **N** English News Articles
          articles = None
          m = re.search(
              r"from\s+\*\*(\d+)\*\*\s+English\s+News\s+Articles",
              md,
              flags=re.I,
          )
          if m:
            try:
              articles = int(m.group(1))
            except ValueError:
              articles = None

          # published between **start** & **end**
          edition_date = None
          m = re.search(
              r"published\s+between\s+\*\*(\d{4}-\d{2}-\d{2})\*\*\s*&\s*\*\*(\d{4}-\d{2}-\d{2})\*\*",
              md,
              flags=re.I,
          )
          if m:
            end_str = m.group(2)
            try:
              edition_date = datetime.strptime(end_str, "%Y-%m-%d").date()
            except Exception:
              edition_date = None

          if last_updated is None:
            last_updated = datetime.now(ZoneInfo(TZ_NAME))
          if edition_date is None:
            edition_date = last_updated.date()

          pub_dt_local = last_updated
          pub_dt_utc = pub_dt_local.astimezone(timezone.utc)
          pub_rfc2822 = email.utils.format_datetime(pub_dt_utc)
          pub_iso = pub_dt_utc.replace(microsecond=0).isoformat().replace("+00:00", "Z")

          # --- Clean markdown for feed body ---
          lines = md.splitlines()
          cleaned = []
          stop = False

          for line in lines:
            if stop:
              continue

            stripped = line.strip()

            if stripped.startswith("## Model Prompt"):
              stop = True
              continue

            if stripped.startswith("# ") and "Sri Lanka This Week" in stripped:
              continue

            if "![LastUpdated]" in stripped or "last_updated-" in stripped:
              continue

            cleaned.append(line)

          md_clean = "\n".join(cleaned).strip()

          # 4. Insert horizontal rules before each subsequent "##" to visually separate sections
          #    This yields <hr /> between digest items in HTML, which most readers render clearly.
          lines = md_clean.splitlines()
          out_lines = []
          first_h2_seen = False

          for line in lines:
            if line.startswith("## "):
              if first_h2_seen:
                out_lines.append("")      # ensure blank line
                out_lines.append("---")   # markdown hr
                out_lines.append("")
              first_h2_seen = True
            out_lines.append(line)

          md_spaced = "\n".join(out_lines).strip()

          # Convert to HTML
          html = markdown(
              md_spaced,
              extensions=["fenced_code", "tables", "sane_lists"],
              output_format="html5",
          ).strip()

          # --- Titles & IDs ---
          feed_title = "Sri Lanka This Week"
          title_parts = [feed_title, str(edition_date)]
          if articles:
            title_parts.append(f"{articles} sources")
          item_title = " — ".join(title_parts)

          item_id = f"lk-news-weekly-{edition_date.isoformat()}-{pub_dt_utc.strftime('%H%M%S')}"

          # --- Build RSS 2.0 ---
          doc = Document()

          rss_el = doc.createElement("rss")
          rss_el.setAttribute("version", "2.0")
          doc.appendChild(rss_el)

          channel_el = doc.createElement("channel")
          rss_el.appendChild(channel_el)

          def add_text_el(parent, name, text):
            el = doc.createElement(name)
            el.appendChild(doc.createTextNode(text))
            parent.appendChild(el)

          add_text_el(channel_el, "title", feed_title)
          add_text_el(channel_el, "link", SRC_REPO)
          add_text_el(
              channel_el,
              "description",
              "Weekly AI-assisted Sri Lanka news digest.",
          )
          add_text_el(channel_el, "language", "en-LK")
          add_text_el(channel_el, "pubDate", pub_rfc2822)
          add_text_el(channel_el, "lastBuildDate", pub_rfc2822)

          item_el = doc.createElement("item")
          channel_el.appendChild(item_el)

          add_text_el(item_el, "title", item_title)
          add_text_el(item_el, "link", SRC_README)

          guid_el = doc.createElement("guid")
          guid_el.setAttribute("isPermaLink", "false")
          guid_el.appendChild(doc.createTextNode(item_id))
          item_el.appendChild(guid_el)

          add_text_el(item_el, "pubDate", pub_rfc2822)

          desc_el = doc.createElement("description")
          cdata = doc.createCDATASection("\n" + html + "\n")
          desc_el.appendChild(cdata)
          item_el.appendChild(desc_el)

          pretty_rss = doc.toprettyxml(indent="  ", encoding="utf-8")
          with open("feed.xml", "wb") as f:
            f.write(pretty_rss)

          # --- Build JSON Feed 1.1 ---
          feed_obj = {
              "version": "https://jsonfeed.org/version/1.1",
              "title": feed_title,
              "home_page_url": SRC_REPO,
              "feed_url": f"{pages_base}/feed.json",
              "language": "en-LK",
              "items": [
                  {
                      "id": item_id,
                      "url": SRC_README,
                      "title": item_title,
                      "content_html": html,
                      "date_published": pub_iso,
                  }
              ],
          }

          with open("feed.json", "w", encoding="utf-8") as f:
            json.dump(feed_obj, f, ensure_ascii=False, indent=2)
            f.write("\n")

          # --- Simple index.html ---
          index_html = f"""<!doctype html>
          <html lang="en">
          <head>
            <meta charset="utf-8">
            <title>{feed_title} — Feeds</title>
          </head>
          <body>
            <h1>{feed_title} — Feeds</h1>
            <p>Edition: {edition_date} · Published (Colombo): {pub_dt_local.isoformat()}</p>
            <ul>
              <li><a href="feed.xml">RSS 2.0 feed</a></li>
              <li><a href="feed.json">JSON Feed 1.1</a></li>
              <li>Source: <a href="{SRC_README}">Upstream README</a></li>
            </ul>
          </body>
          </html>
          """
          with open("index.html", "w", encoding="utf-8") as f:
            f.write(index_html.strip() + "\n")
          PY

      - name: Commit and push artifacts
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
          git add feed.xml feed.json index.html || true
          if git diff --cached --quiet; then
            echo "No changes to commit."
            exit 0
          fi
          git commit -m "Update feeds from upstream README (clean spacing)"
          git push
